{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Analytical Information Systems*\n",
    "\n",
    "# Tutorial 2 - Data Integration\n",
    "\n",
    "Matthias Griebel<br>\n",
    "Lehrstuhl für Wirtschaftsinformatik und Informationsmanagement\n",
    "\n",
    "SS 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc": true
   },
   "source": [
    "<h1>Agenda<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1-Recap-of-Data-Integration\" data-toc-modified-id=\"1-Recap-of-Data-Integration-1\">1 Recap of Data Integration</a></span></li><li><span><a href=\"#2-Data-Extraction\" data-toc-modified-id=\"2-Data-Extraction-2\">2 Data Extraction</a></span></li><li><span><a href=\"#3-Data-Transformation\" data-toc-modified-id=\"3-Data-Transformation-3\">3 Data Transformation</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Data-Cleansing\" data-toc-modified-id=\"3.1-Data-Cleansing-3.1\">3.1 Data Cleansing</a></span></li><li><span><a href=\"#3.2-Data-Harmonization\" data-toc-modified-id=\"3.2-Data-Harmonization-3.2\">3.2 Data Harmonization</a></span></li><li><span><a href=\"#3.3-Data-Combination\" data-toc-modified-id=\"3.3-Data-Combination-3.3\">3.3 Data Combination</a></span></li><li><span><a href=\"#3.4-Enrich-the-data\" data-toc-modified-id=\"3.4-Enrich-the-data-3.4\">3.4 Enrich the data</a></span></li></ul></li><li><span><a href=\"#4-Data-Loading\" data-toc-modified-id=\"4-Data-Loading-4\">4 Data Loading</a></span></li><li><span><a href=\"#5-Exam-Questions\" data-toc-modified-id=\"5-Exam-Questions-5\">5 Exam Questions</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-Exam-AIS-SS-2018,-Question-1\" data-toc-modified-id=\"5.1-Exam-AIS-SS-2018,-Question-1-5.1\">5.1 Exam AIS SS 2018, Question 1</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1 Recap of Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Definition [Gartner IT Glossary](https://www.gartner.com/it-glossary/data-integration-tools/)\n",
    "\n",
    "*'[...] __data integration__ comprises the practices, architectural techniques and tools for achieving the __consistent access and delivery__ of data across the spectrum of data subject areas and data structure types in the enterprise to meet the data consumption requirements of all applications and business processes.'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Identify relevant databases\n",
    "\n",
    "- First step of data integration\n",
    "- External and internal data sources comprise \n",
    "    - relational and non-relational databases, \n",
    "    - XML, JSON\n",
    "    - flat files (e.g., .csv)\n",
    "    - and many more<br>\n",
    "\n",
    "- Two types of heterogeneity will inevitably emerge: Schema and data-level<br>\n",
    "\n",
    "__How do get the data ready for analysis?__\n",
    "\n",
    "<img src=\"images/02/BIStack_ds.png\" style=\"width:80%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Data Warehousing: ETL\n",
    "\n",
    "*from [Wikipedia](https://en.wikipedia.org/wiki/Extract,_transform,_load)*:\n",
    "\n",
    "\"[...] extract, transform, load (ETL) is the general procedure of copying data from one or more sources into a destination system which represents the data differently from the source(s).\"\n",
    "- __Data extraction__ involves extracting data from homogeneous or heterogeneous sources\n",
    "- __Data transformation__ processes data by data cleansing and transforming them into a proper storage format/structure for the purposes of querying and analysis\n",
    "- __Data loading__ describes the insertion of data into the final target database such as an operational data store, a data mart, or a data warehouse.\n",
    "\n",
    "<img src=\"images/02/BIStack_etl.png\" style=\"width:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Today's Focus\n",
    "\n",
    "We will learn how to...\n",
    "- read data from different sources\n",
    "- cleanse and transform the data sets\n",
    "- combine the data sets\n",
    "- enrich the data sets\n",
    "- load the data into a database management system\n",
    "- perform queries on a database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 Data Extraction\n",
    "\n",
    "<img src=\"https://readr.tidyverse.org/logo.png\" style=\"width:15%; float:right\">\n",
    "\n",
    "- The **readr** package provides a fast and friendly way <br> for reading rectangular data \n",
    "    - File formats: .csv, .tsv, and .fwf\n",
    "    - Part of the core tidyverse\n",
    "```R\n",
    "# Example\n",
    "read_csv(\"file.csv\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Packages for other file formats**\n",
    "    - haven - SPSS, Stata, and SAS files \n",
    "    - readxl - excel files (.xls and .xlsx) \n",
    "    - DBI - databases\n",
    "    - jsonlite - json\n",
    "    - xml2 - XML\n",
    "    - httr - Web APIs\n",
    "    - rvest - HTML (Web Scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Data Import Cheat Sheet\n",
    "<img src=\"https://www.rstudio.com/wp-content/uploads/2018/08/data-import-600x464.png\" style=\"width:50%; float:right\">\n",
    "\n",
    "- How to read in flat files \n",
    "- Work with the results as tibbles\n",
    "- Reshape messy data\n",
    "\n",
    "[Download here](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Read the data*\n",
    "\n",
    "You are provided with a set of operational data from a retail company. \n",
    "\n",
    "- Transaction data (Comma Delimited Files): \n",
    "    - *'transactions_eng.csv'*\n",
    "    - *'transactions_ger.csv'*\n",
    "   \n",
    "- Customer data (Semi-colon Delimited Files)\n",
    "    - *'customers.csv*\n",
    "    - *'customers_usa.csv*\n",
    "\n",
    "- Product data (Excel Files)\n",
    "    - *'products_convenience.xlsx'*\n",
    "    - *'products.xlsx*\n",
    "    \n",
    "Load the provided files. All files are stored in the folder *'data/T02/'*\n",
    "- you can use `setwd()` to change your working directory to 'data/T02'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse) # includes the readr package\n",
    "library(readxl) # excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "setwd('data/T02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Read the data using the appropriate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Take a look at the data \n",
    "```R\n",
    "head()\n",
    "sample_n()\n",
    "```\n",
    "- Check that all data is read in correctly\n",
    "```R\n",
    "nrow(), ncol(), colnames()\n",
    "```\n",
    "- Understand the rows and columns (observations and variables)\n",
    "```R\n",
    "glimpse()\n",
    "summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data transformation converts the data into a proper storage format/structure for the purposes of querying and analysis\n",
    "- Data cleansing \n",
    "    - Correct syntactical or semantical defects\n",
    "- Data harmonization\n",
    "    - Solving schema heterogeneity \n",
    "    - Solving data-level heterogeneity\n",
    "- Data combination\n",
    "    - Combine the harmonized data sets\n",
    "- Data enrichment\n",
    "    - Calculate frequently required (business) key figures as separate attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 Data Cleansing \n",
    "\n",
    "__Correction of syntactical or semantical defects__\n",
    "\n",
    "Depending on the degree of automation in the defect detection and defect correction we distinguish between three classes of defects.<br><br>\n",
    "\n",
    "| <br>               | Automated Correction         | Manual Correction            |\n",
    "|--------------------|------------------------------|------------------------------|\n",
    "| Automated Detection| 1<sup>st</sup> class defects | 2<sup>nd</sup> class defects |\n",
    "| Manual Detection   | -                            | 3<sup>rd</sup> class defects |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1<sup>st</sup> class deficiencies\n",
    "\n",
    "Syntactic and semantic deficiencies that are known in advance or can be anticipated.\n",
    "- Syntactic: format, special characters, …\n",
    "- Semantic: missing values in operating systems due to planned maintenance, …\n",
    "\n",
    "→ Deficiencies can be automatically resolved by implementing transformation rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - 1<sup>st</sup> class deficiencies*\n",
    "\n",
    "1. Find the syntactic 1st class deficiencies in the products convenience data sets\n",
    "    - `products_convenience`: look at price and costs\n",
    "    - `customers_usa`: look at the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - 1<sup>st</sup> class deficiencies*  \n",
    "\n",
    "2. Implement transformation rules to resolve the deficiencies\n",
    "    - Transformation rules can be implemented as pipes\n",
    "    - You will have to use mutate() in combination with *str_replace()* and/or *str_split()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2<sup>nd</sup> class deficiencies\n",
    "\n",
    "Deficiencies that can be automatically identified but have to be removed manually\n",
    "\n",
    "- Syntactic: prior unknown syntactic error are identified for the first time and transferred into transformation rules\n",
    "- Semantic: deficiencies can be identified by automatic plausibility checks or pattern recognition algorithms\n",
    "\n",
    "→ Deficiencies are usually due to errors in the data source, corrective action must be taken at the operational source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - 2<sup>nd</sup> class deficiencies*\n",
    "\n",
    "1. Perform plausibility checks (min, mean, max, …) to identify deficiencies in the product data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - 2<sup>nd</sup> class deficiencies*\n",
    "\n",
    "2. Implement transformation rules to resolve the deficiencies. <br> If you identify errors or missing values you can either:\n",
    "    - Keep the errors / missing values\n",
    "    - Remove the observations\n",
    "    - Impute the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3<sup>rd</sup> class deficiencies\n",
    "\n",
    "Semantic deficiencies that can only be manually identified and resolved.\n",
    "- Errors in the data set that can only be identified by domain experts\n",
    "\n",
    "→ Prompt correction of the deficiencies can be supported by software tools (Workflow-Management-Systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - 3<sup>rd</sup> class deficiencies*\n",
    "\n",
    "1. Find the semantic 3<sup>rd</sup> class deficiencies in the customer data\n",
    "    - `costomer`: Take a closer look at the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - 3<sup>rd</sup> class deficiencies*\n",
    "\n",
    "2. Resolve the deficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 Data Harmonization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Solving Schema Heterogeneity\n",
    "\n",
    "Schemas are created by different people whose states and styles are different\n",
    "- Same concept, but different names for tables and attributes\n",
    "    - rating vs classification\n",
    "- Multiple attributes in first schema relate to a single attribute in the other\n",
    "    - basePrice and taxRate relate to price\n",
    "- Tabular organization of schemas can be quite different\n",
    "    - One table in DB1 vs three tables in DB2\n",
    "- Coverage and level of details can also differ significantly\n",
    "    - Daily sales data vs. monthly sales data\n",
    "    - High-level information (movie name, playtime) vs. detailed meta data (director, genre, rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Data Harmonization*\n",
    "\n",
    "1. Find and harmonize schema heterogeneity in transaction data sets\n",
    "    - Look at the attribute names\n",
    "    - Adjust the transactions_ger to the schema of transactions_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Solving Data-level  Heterogeneity\n",
    "Data coming from different sources rarely joins perfectly\n",
    "\n",
    "Typical reasons include\n",
    "- Differently coded data\n",
    "    - identical attribute names and identical meanings but different domains or value ranges (e.g., gender coded as “m / f” or “male / female”)\n",
    "- Synonyms\n",
    "    - Attributes that have different names but the same meaning and domain (e.g., “client” or “customer”)\n",
    "- Homonyms: \n",
    "    - Attributes have the same attribute names, but have different meanings (e.g., “partner” = “customer” or “partner” = “supplier”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Data Harmonization*\n",
    "\n",
    "2. Find and harmonize data-level heterogeneity in the customer data sets\n",
    "    - Take a closer look to the variables names as well as the variable values\n",
    "    - Adjust the `customers_usa` to the schema of `customers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3 Data Combination\n",
    "\n",
    "Combine the harmonized data sets into an appropriate format/structure for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Combine the data* \n",
    "\n",
    "1. Combine the harmonised data sets\n",
    "    - Create three new data sets: `customers`, `transactions`, `products`\n",
    "    - Use *bind_rows()* for binding multiple data frames by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Combine the data* \n",
    "\n",
    "2. Join the three data sets into one data final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.4 Enrich the data\n",
    "\n",
    "- Business key figures are calculated and integrated into the data basis as separate attributes\n",
    "- Example: Calculation of weekly contribution margins at product level and annual contribution margins at store level\n",
    "- Advantages\n",
    "    - Calculable response time behavior for later queries based on the advance calculation\n",
    "    - Guaranteed consistency of the calculated values, since they are only formed once across all applications\n",
    "    - Establishment of coordinated business management instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Enrich the data* \n",
    "\n",
    "2. Create two new variables:\n",
    "    - revenue per transaction\n",
    "    - profit per transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4 Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Data loading__ describes the insertion of data into the final target database such as an operational data store, a data mart, or a data warehouse (e.g., AWS Redshift or Apache Hive)\n",
    "\n",
    "- A database is an organized collection of data\n",
    "    - typically cleaned and structured data\n",
    "- The data is stored \n",
    "- Database management system (DBMS)\n",
    "    - allows to store, modify, and extract information from a database MySQL, ORACLE, MS SQL, DB2, MS ACCESS, Informix\n",
    "- RDBMS stands for Relational Database Management System\n",
    "    - data is stored in database objects called tables\n",
    "    - tables can be joined through keys and indexes\n",
    "- SQL is used to work with DBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What is SQL?\n",
    "\n",
    "- A standard language for accessing and manipulating data in databases\n",
    "    - SQL stands for Structured Query Language\n",
    "    - allows retrieving and manipulating data as well as administrative operations\n",
    "\n",
    "- A typical SQL command\n",
    "```SQL\n",
    "\tSELECT <column names separated by comma>\n",
    "    FROM <database table>\n",
    "\tWHERE <condition>\n",
    "    GROUP BY <column name>\n",
    "    ORDER BY <column name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using differnte query languages in R\n",
    "\n",
    "- The *DBI* (Database Interface) package allows communication between R and relational database management systems\n",
    "    - Using a DBI-compliant interface, the *RSQLite* embeds the SQLite database engine in R\n",
    "    - SQLite is a public-domain, single-user, very light-weight database engine that implements a decent subset of the SQL 92 standard,\n",
    "- The packages *dbplyr* (part of the *tidyverse*) is designed to work with database tables as if they were local data frames\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/matjesg/AIS_2019/raw/master/notebooks/images/01/aris.png\" style=\"width:30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We’ll first create an in-memory SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con <- DBI::dbConnect(RSQLite::SQLite(), \":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and copy over our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to(con, data_enriched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now you can retrieve a table using `tbl()` . Printing it just retrieves the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db <- tbl(con, \"data_enriched\")\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- (Lazily) generate query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db %>%\n",
    "    filter(payment == 'cash') %>%\n",
    "    summarise(MeanAmount = mean(amount, na.rm = TRUE)) -> summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- See query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary %>% show_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Execute query and retrieve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary %>% collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### *Up to you - Analyze the data* \n",
    "\n",
    "How much profit did the company realize in 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5 Exam Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.1 Exam AIS SS 2018, Question 1\n",
    "\n",
    "__Data Engineering & Integration (10 points)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(a) __Getting orders in order__: You are working for a major online retailer who is interested in optimizing internal logistics processes. A key problem in this context is the handling of orders with a single line item vs. orders with multiple line items.\n",
    "\n",
    "The cornerstone of your analysis is an orders table with the following structure:\n",
    "\n",
    "| productID | quantity | orderID |\n",
    "|-----------|----------|---------|\n",
    "| ...       | ...      | ...     |\n",
    "\n",
    "i. (1 points) Explain (verbally or in pseudo code) how you would identify the number of orders with a single line item from this data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "i. (2 points) The frontend reporting tool used by the logistics department cannot handle data sets with more than 1 million rows. Yet your order table has many more rows. Recognizing that individual product IDs are not crucial for the logistics process analysis (handling times are determined by the number of products in an order) you are approached to provide a \\textit{compact representation which retains the structure (number of line items) of the order invoices}. Explain how this can be achieved by means of clever aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(b) (3 Points) __Here comes the sun__: You are working for a local crime investigation unit and your current assignment involves a series of burglary cases. The head of the investigation wants to know which share of the of the break-ins took place during night-time (i.e., between sunset and sunrise). You are provided with a table of the time and date for the burglary events as well as a table of sunrise and sunset times for all dates in the time period under consideration. Provide an analytic pipeline (verbally or in pseudo code) to answer this question.\n",
    "\n",
    "| date | time | crimeID |\n",
    "|------|------|---------|\n",
    "| ...  | ...  | ...     |\n",
    "\n",
    "| date | sunriseTime | sunsetTime |\n",
    "|------|-------------|------------|\n",
    "| ...  | ...         | ...        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(c) (2 points) __Difficulties__ of data integration arise from different perspectives. Discuss the systems-level as well as social reasons which render data integration a hard task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(d) (2 points) __Scalability__ of naively executed string matching operations is problematic for large data sets. Explain why. What is a typical workaround?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  },
  "rise": {
   "enable_chalkboard": false,
   "overlay": "<div class='logo'><img src='images/uniwue4c.png'></div>",
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Agenda",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
